import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import openai
import io
import json
import warnings
from plotly.subplots import make_subplots
from sklearn.ensemble import IsolationForest
from statsmodels.tsa.seasonal import seasonal_decompose
from pandas.api.types import is_datetime64_any_dtype

warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="ü§ñ AI Data Analyzer Pro",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ó–∞–≥—Ä—É–∑–∫–∞ API –∫–ª—é—á–∞ OpenAI –∏–∑ Streamlit Secrets
if 'OPENAI_API_KEY' in st.secrets:
    openai.api_key = st.secrets['OPENAI_API_KEY']
else:
    openai.api_key = ""

# –¢–µ–º–∞ –¥–Ω–µ–≤–Ω–∞—è (–±–µ–∑ –≤—ã–±–æ—Ä–∞)
st.markdown("""
    <style>
        .stApp { background-color: #f0f2f6; color: #000000; }
        footer { visibility: hidden; }
    </style>
""", unsafe_allow_html=True)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
st.title("ü§ñ AI Data Analyzer Pro")
st.markdown("""
    <div style="background-color:#ffffff;padding:10px;border-radius:10px;margin-bottom:20px;">
    <p style="color:#333;font-size:18px;">üöÄ <b>–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å AI-powered –∏–Ω—Å–∞–π—Ç–∞–º–∏</b></p>
    <p style="color:#666;">–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV, Excel –∏–ª–∏ JSON ‚Äî –ø–æ–ª—É—á–∏—Ç–µ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é</p>
    </div>
""", unsafe_allow_html=True)

@st.cache_data(show_spinner="–ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ... ‚è≥", ttl=3600, max_entries=3)
def load_data(uploaded_file):
    try:
        file_bytes = uploaded_file.read()
        if uploaded_file.name.endswith('.csv'):
            return pd.read_csv(io.BytesIO(file_bytes), encoding_errors='ignore')
        elif uploaded_file.name.endswith(('.xlsx', '.xls')):
            return pd.read_excel(io.BytesIO(file_bytes))
        elif uploaded_file.name.endswith('.json'):
            data = json.loads(file_bytes.decode('utf-8'))
            return pd.json_normalize(data)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")
        return None

def reduce_mem_usage(df):
    start_mem = df.memory_usage().sum() / 1024**2
    for col in df.columns:
        col_type = df[col].dtype
        if col_type != object:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                else:
                    df[col] = df[col].astype(np.int64)
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
    end_mem = df.memory_usage().sum() / 1024**2
    st.sidebar.info(f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏: {start_mem:.2f} MB ‚Üí {end_mem:.2f} MB (—Å—ç–∫–æ–Ω–æ–º–ª–µ–Ω–æ {100*(start_mem-end_mem)/start_mem:.1f}%)")
    return df

@st.cache_data(show_spinner="–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ... üîç", ttl=600)
def analyze_with_ai(df):
    try:
        analysis = f"### üìä –û–±—â–∏–π –æ–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö\n"
        analysis += f"- **–°—Ç—Ä–æ–∫–∏:** {df.shape[0]}\n"
        analysis += f"- **–ö–æ–ª–æ–Ω–∫–∏:** {df.shape[1]}\n"
        analysis += f"- **–û–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö:** {df.memory_usage().sum() / 1024**2:.2f} MB\n\n"

        num_cols = df.select_dtypes(include=np.number).columns
        if len(num_cols) > 0:
            analysis += "### üî¢ –ß–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ\n"
            stats = df[num_cols].describe().transpose()
            stats['skew'] = df[num_cols].skew()
            analysis += stats[['mean', 'std', 'min', '50%', 'max', 'skew']].to_markdown()

        cat_cols = df.select_dtypes(exclude=np.number).columns
        if len(cat_cols) > 0:
            analysis += "\n\n### üî§ –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n"
            for col in cat_cols:
                analysis += f"- **{col}**: {df[col].nunique()} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n"

        missing = df.isnull().sum()
        if missing.sum() > 0:
            analysis += "\n\n### ‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n"
            missing_percent = missing[missing > 0] / len(df) * 100
            missing_df = pd.DataFrame({'–ö–æ–ª–æ–Ω–∫–∞': missing_percent.index,
                                      '–ü—Ä–æ–ø—É—Å–∫–∏': missing[missing > 0],
                                      '%': missing_percent.values.round(1)})
            analysis += missing_df.to_markdown(index=False)

        if len(num_cols) > 1:
            corr = df[num_cols].corr().abs().unstack().sort_values(ascending=False)
            strong_corr = corr[(corr > 0.7) & (corr < 1)].drop_duplicates()
            if len(strong_corr) > 0:
                analysis += "\n\n### üîó –°–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏\n"
                for pair, value in strong_corr.items():
                    analysis += f"- {pair[0]} –∏ {pair[1]}: {value:.2f}\n"

        return analysis
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"

@st.cache_data(show_spinner="–ò—â—É –∞–Ω–æ–º–∞–ª–∏–∏... üïµÔ∏è", ttl=300)
def detect_anomalies(df, column):
    try:
        if len(df) > 10000:
            sample = df.sample(min(5000, len(df)))
        else:
            sample = df

        model = IsolationForest(contamination=0.05, random_state=42, n_jobs=-1)
        model.fit(sample[[column]])
        df['anomaly'] = model.predict(df[[column]])
        anomalies = df[df['anomaly'] == -1]
        return anomalies
    except:
        return None

@st.cache_data(show_spinner="–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã... ‚è≥", ttl=300)
def time_series_analysis(df, date_col, value_col):
    try:
        df = df.set_index(date_col).sort_index()
        if len(df) > 1000:
            df = df.resample('D').mean()

        decomposition = seasonal_decompose(df[value_col], period=min(12, len(df)//2))

        fig = make_subplots(rows=4, cols=1, shared_xaxes=True)
        fig.add_trace(go.Scatter(x=df.index, y=df[value_col], name='–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ'), row=1, col=1)
        fig.add_trace(go.Scatter(x=decomposition.trend.index, y=decomposition.trend, name='–¢—Ä–µ–Ω–¥'), row=2, col=1)
        fig.add_trace(go.Scatter(x=decomposition.seasonal.index, y=decomposition.seasonal, name='–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å'), row=3, col=1)
        fig.add_trace(go.Scatter(x=decomposition.resid.index, y=decomposition.resid, name='–û—Å—Ç–∞—Ç–∫–∏'), row=4, col=1)

        fig.update_layout(height=800, title_text="–î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞")
        return fig
    except:
        return None

@st.cache_data(show_spinner="–ì–µ–Ω–µ—Ä–∏—Ä—É—é AI –∏–Ω—Å–∞–π—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏... ü§ñ", ttl=600)
def generate_ai_insights_and_viz(df):
    if not openai.api_key:
        return "üîë –ö–ª—é—á OpenAI API –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ Secrets.", None, None, None, None, None, None

    prompt = (
        f"–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö. –°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–∞–Ω–Ω—ã–º.\n"
        f"–î–∞–Ω–Ω—ã–µ: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫.\n"
        f"–ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}.\n"
        f"–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\n{df.head().to_dict()}\n\n"
        f"–ù–∞–ø–∏—à–∏ –∏–Ω—Å–∞–π—Ç—ã –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –æ–¥–∏–Ω —Ç–∏–ø –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–∑: –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞, —Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞, 3D scatter, –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥, candlestick, –∞–Ω–æ–º–∞–ª–∏–∏, —Ç–æ—á–µ—á–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞.\n"
        f"–û—Ç–≤–µ—Ç—å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ: "
        f'{{"insights": "...", "viz_type": "...", "x_axis": "...", "y_axis": "...", "z_axis": "...", "color": "...", "size": "..."}}. '
        f"–ï—Å–ª–∏ –Ω–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–µ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏, –ø—Ä–æ—Å—Ç–æ 'viz_type' –æ—Å—Ç–∞–≤—å –ø—É—Å—Ç—ã–º."
    )

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=600
        )
        text = response['choices'][0]['message']['content']

        try:
            parsed = json.loads(text)
            insights = parsed.get('insights', '')
            viz_type = parsed.get('viz_type', None)
            x_axis = parsed.get('x_axis', None)
            y_axis = parsed.get('y_axis', None)
            z_axis = parsed.get('z_axis', None)
            color = parsed.get('color', None)
            size = parsed.get('size', None)
            return insights, viz_type, x_axis, y_axis, z_axis, color, size
        except Exception:
            # –ï—Å–ª–∏ JSON –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
            return text, None, None, None, None, None, None

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ OpenAI: {str(e)}", None, None, None, None, None, None

def map_column_name(col_name, df_columns):
    """
    –ú–∞–ø–ø–∏–Ω–≥ —Ä—É—Å—Å–∫–∏—Ö –∏–ª–∏ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –≤ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –∏–∑ df.columns.
    –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.
    """
    if not col_name:
        return ""
    mapping_dict = {
        "–≤–æ–∑—Ä–∞—Å—Ç": "age",
        "–ø–æ–ª": "sex",
        "—Ö–æ–ª–µ—Å—Ç–µ—Ä–∏–Ω": "chol",
        "—Ü–µ–ª–µ–≤–∞—è": "target",
        "–¥–∞–≤–ª–µ–Ω–∏–µ": "trestbps",
        "–±–æ–ª—å –≤ –≥—Ä—É–¥–∏": "cp",
        "—Å–∞—Ö–∞—Ä –≤ –∫—Ä–æ–≤–∏": "fbs",
        "—ç–ª–µ–∫—Ç—Ä–æ–∫–∞—Ä–¥–∏–æ–≥—Ä–∞–º–º–∞": "restecg",
        "–º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø—É–ª—å—Å": "thalach",
        "–∏—à–µ–º–∏—è": "exang",
        "—Å—Ç–∞—Ä–µ–Ω–∏–µ": "oldpeak",
        "–Ω–∞–∫–ª–æ–Ω": "slope",
        "–∫–∞–ª—Ü–∏–π": "ca",
        "—Ç–∞–ª–∞—Å—Å–µ–º–∏—è": "thal",
        "—Ü–µ–ª—å": "target",
        "–≤–æ–∑—Ä–∞—Å—Ç": "age",
        "—Ü–≤–µ—Ç": "color",
        "—Ä–∞–∑–º–µ—Ä": "size",
        # –î–æ–±–∞–≤–ª—è–π –ø–æ –º–µ—Ä–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    }
    key = col_name.lower()
    if key in mapping_dict and mapping_dict[key] in df_columns:
        return mapping_dict[key]
    if col_name in df_columns:
        return col_name
    return ""

def build_visualization(df, viz_type, x, y, z, color, size):
    if not viz_type or viz_type.lower() == "":
        return None

    try:
        if viz_type.lower() == "—Ç–æ—á–µ—á–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞":
            if z and z in df.columns:
                fig = px.scatter_3d(df, x=x, y=y, z=z, color=color if color in df.columns else None,
                                    size=size if size in df.columns else None,
                                    title="3D –¢–æ—á–µ—á–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞")
            else:
                fig = px.scatter(df, x=x, y=y, color=color if color in df.columns else None,
                                 size=size if size in df.columns else None,
                                 title="–¢–æ—á–µ—á–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞")
            return fig

        elif viz_type.lower() == "–≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞":
            fig = px.histogram(df, x=x, color=color if color in df.columns else None,
                               title="–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞")
            return fig

        elif viz_type.lower() == "—Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞":
            numeric_cols = df.select_dtypes(include=np.number).columns
            corr = df[numeric_cols].corr()
            fig = px.imshow(corr, text_auto=True, title="–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π")
            return fig

        elif viz_type.lower() == "–≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥":
            if x in df.columns and y in df.columns and is_datetime64_any_dtype(df[x]):
                fig = px.line(df, x=x, y=y, color=color if color in df.columns else None,
                              title="–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥")
                return fig

        elif viz_type.lower() == "–∞–Ω–æ–º–∞–ª–∏–∏":
            if y in df.columns:
                anomalies = detect_anomalies(df, y)
                if anomalies is not None and len(anomalies) > 0:
                    fig = px.scatter(df, x=x if x in df.columns else df.index, y=y,
                                     color=(df['anomaly'] == -1).map({True: '–ê–Ω–æ–º–∞–ª–∏—è', False: '–ù–æ—Ä–º–∞'}),
                                     title="–ê–Ω–æ–º–∞–ª–∏–∏")
                    return fig

        # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É...

        return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞: {str(e)}")
        return None


def main():
    uploaded_file = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV, Excel –∏–ª–∏ JSON", type=["csv", "xlsx", "xls", "json"])

    if uploaded_file is not None:
        df = load_data(uploaded_file)
        if df is None or df.empty:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π.")
            return

        df = reduce_mem_usage(df)
        st.dataframe(df.head(50))

        with st.spinner("–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º AI –∏–Ω—Å–∞–π—Ç—ã –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏..."):
            insights, viz_type, x_axis, y_axis, z_axis, color, size = generate_ai_insights_and_viz(df)

        st.markdown("## ü§ñ AI –ò–Ω—Å–∞–π—Ç—ã")
        if insights:
            st.markdown(insights)
        else:
            st.info("AI –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –∏–Ω—Å–∞–π—Ç—ã.")

        st.markdown("## üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è")

        # –ú–∞–ø–ø–∏–Ω–≥ –Ω–∞–∑–≤–∞–Ω–∏–π –∏–∑ AI –æ—Ç–≤–µ—Ç–∞ –≤ —Ä–µ–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ —Å—Ç–æ–ª–±—Ü–æ–≤
        x = map_column_name(x_axis, df.columns)
        y = map_column_name(y_axis, df.columns)
        z = map_column_name(z_axis, df.columns)
        color_mapped = map_column_name(color, df.columns)
        size_mapped = map_column_name(size, df.columns)

        fig = build_visualization(df, viz_type, x, y, z, color_mapped, size_mapped)

        if fig is not None:
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("AI –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –∏–ª–∏ —Ç–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.")

    else:
        st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∞.")

if __name__ == "__main__":
    main()
