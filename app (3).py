import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import openai
import io
import json
import warnings
from sklearn.ensemble import IsolationForest
from pandas.api.types import is_numeric_dtype, is_categorical_dtype

warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="InsightBot Pro",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ó–∞–≥—Ä—É–∑–∫–∞ API –∫–ª—é—á–∞ OpenAI –∏–∑ Streamlit Secrets
if 'OPENAI_API_KEY' in st.secrets:
    openai.api_key = st.secrets['OPENAI_API_KEY']
else:
    openai.api_key = ""

# –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è
st.markdown("""
    <style>
        .stApp { background-color: #f0f2f6; color: #000000; }
        footer { visibility: hidden; }
    </style>
""", unsafe_allow_html=True)

st.title("InsightBot Pro")
st.markdown("""
    <div style="background-color:#ffffff;padding:10px;border-radius:10px;margin-bottom:20px;">
    <p style="color:#333;font-size:18px;">üöÄ <b>–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å AI-powered –∏–Ω—Å–∞–π—Ç–∞–º–∏</b></p>
    <p style="color:#666;">–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV, Excel –∏–ª–∏ JSON ‚Äî –ø–æ–ª—É—á–∏—Ç–µ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–æ–π –∏ —Å–æ–≤–µ—Ç–∞–º–∏</p>
    </div>
""", unsafe_allow_html=True)

@st.cache_data(show_spinner="–ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ... ‚è≥", ttl=3600, max_entries=3)
def load_data(uploaded_file):
    try:
        file_bytes = uploaded_file.read()
        if uploaded_file.name.endswith('.csv'):
            return pd.read_csv(io.BytesIO(file_bytes), encoding_errors='ignore')
        elif uploaded_file.name.endswith(('.xlsx', '.xls')):
            return pd.read_excel(io.BytesIO(file_bytes))
        elif uploaded_file.name.endswith('.json'):
            data = json.loads(file_bytes.decode('utf-8'))
            return pd.json_normalize(data)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")
        return None

def reduce_mem_usage(df):
    start_mem = df.memory_usage().sum() / 1024**2
    for col in df.columns:
        col_type = df[col].dtype
        if col_type != object:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                else:
                    df[col] = df[col].astype(np.int64)
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
    end_mem = df.memory_usage().sum() / 1024**2
    st.sidebar.info(f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏: {start_mem:.2f} MB ‚Üí {end_mem:.2f} MB (—Å—ç–∫–æ–Ω–æ–º–ª–µ–Ω–æ {100*(start_mem-end_mem)/start_mem:.1f}%)")
    return df

def fill_missing_values(df):
    df_filled = df.copy()
    for col in df_filled.columns:
        if df_filled[col].isnull().sum() > 0:
            if is_numeric_dtype(df_filled[col]):
                df_filled[col].fillna(df_filled[col].median(), inplace=True)
            else:
                mode_val = df_filled[col].mode()
                if not mode_val.empty:
                    df_filled[col].fillna(mode_val[0], inplace=True)
                else:
                    df_filled[col].fillna("Unknown", inplace=True)
    return df_filled

def mark_anomalies(df):
    num_cols = df.select_dtypes(include=np.number).columns
    if len(num_cols) == 0:
        return df
    iso = IsolationForest(contamination=0.05, random_state=42)
    preds = iso.fit_predict(df[num_cols])
    df['anomaly'] = preds
    df['anomaly'] = df['anomaly'].map({1: 0, -1: 1})
    return df

def analyze_with_ai(df):
    try:
        analysis = f"- **–°—Ç—Ä–æ–∫–∏:** {df.shape[0]}\n- **–ö–æ–ª–æ–Ω–∫–∏:** {df.shape[1]}\n- **–û–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö:** {df.memory_usage().sum() / 1024**2:.2f} MB\n\n"
        num_cols = df.select_dtypes(include=np.number).columns
        if len(num_cols) > 0:
            analysis += "### üî¢ –ß–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ\n"
            stats = df[num_cols].describe().transpose()
            stats['skew'] = df[num_cols].skew()
            analysis += stats[['mean', 'std', 'min', '50%', 'max', 'skew']].to_markdown()
        cat_cols = df.select_dtypes(exclude=np.number).columns
        if len(cat_cols) > 0:
            analysis += "\n\n### üÑ§ –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n"
            for col in cat_cols:
                analysis += f"- **{col}**: {df[col].nunique()} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n"
        missing = df.isnull().sum()
        if missing.sum() > 0:
            analysis += "\n\n### ‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n"
            missing_percent = missing[missing > 0] / len(df) * 100
            missing_df = pd.DataFrame({'–ö–æ–ª–æ–Ω–∫–∞': missing_percent.index, '–ü—Ä–æ–ø—É—Å–∫–∏': missing[missing > 0], '%': missing_percent.values.round(1)})
            analysis += missing_df.to_markdown(index=False)
        if len(num_cols) > 1:
            corr = df[num_cols].corr().abs().unstack().sort_values(ascending=False)
            strong_corr = corr[(corr > 0.7) & (corr < 1)].drop_duplicates()
            if len(strong_corr) > 0:
                analysis += "\n\n### üîó –°–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏\n"
                for pair, value in strong_corr.items():
                    analysis += f"- {pair[0]} –∏ {pair[1]}: {value:.2f}\n"
        return analysis
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"

def generate_ai_insights(df):
    if not openai.api_key:
        return "üîë –ö–ª—é—á OpenAI API –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ Secrets."
    prompt = (
        f"–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö. –°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç –ø–æ –¥–∞–Ω–Ω—ã–º.\n"
        f"–î–∞–Ω–Ω—ã–µ: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫.\n"
        f"–ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}.\n"
        f"–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\n{df.head().to_dict()}\n\n"
        f"–î–∞–π –∫—Ä–∞—Ç–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–∞–Ω–Ω—ã–º."
    )
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=1000
        )
        return response['choices'][0]['message']['content']
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ OpenAI API: {str(e)}"

def generate_viz_recommendations(df):
    if not openai.api_key:
        return None
    prompt = f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö. –ü–æ—Å–º–æ—Ç—Ä–∏ –Ω–∞ –∫–æ–ª–æ–Ω–∫–∏ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {list(df.columns)}.
–ü—Ä–µ–¥–ª–æ–∂–∏ 3 –ø—Ä–æ—Å—Ç—ã–µ –∏ –ø–æ–Ω—è—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤. 
–ü–∏—à–∏ –ø–æ-—Ä—É—Å—Å–∫–∏ –∏ –∫–æ—Ä–æ—Ç–∫–æ. –ù–∞–ø—Ä–∏–º–µ—Ä:
- –ü–æ—Å—Ç—Ä–æ–π –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 'Age'
- –ü–æ—Å—Ç—Ä–æ–π scatter plot —Å 'Height' –ø–æ –æ—Å–∏ X –∏ 'Weight' –ø–æ –æ—Å–∏ Y
- –ü–æ—Å—Ç—Ä–æ–π box plot –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 'Salary'
"""
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=1000
        )
        return response['choices'][0]['message']['content']
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ OpenAI API: {e}"

# === UI ===
st.sidebar.header("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏")
uploaded_file = st.sidebar.file_uploader("CSV, Excel –∏–ª–∏ JSON", type=["csv", "xlsx", "xls", "json"])

if uploaded_file:
    df = load_data(uploaded_file)
    if df is not None:
        df = reduce_mem_usage(df)
        st.success(f"–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_file.name} ({df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫)")

        st.subheader("üìÑ –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
        st.dataframe(df.head())

        with st.spinner("\ud83e\uddfc –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—á–∏—â–∞—é –¥–∞–Ω–Ω—ã–µ..."):
            df_clean = fill_missing_values(df)
            df_clean = mark_anomalies(df_clean)

        st.success("\u2705 –î–∞–Ω–Ω—ã–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—á–∏—â–µ–Ω—ã! –î–æ–±–∞–≤–ª–µ–Ω —Å—Ç–æ–ª–±–µ—Ü 'anomaly' (1 ‚Äî –∞–Ω–æ–º–∞–ª–∏—è, 0 ‚Äî –Ω–æ—Ä–º–∞).")
        st.subheader("\ud83d\udccb –û—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–ø–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫)")
        st.dataframe(df_clean.head(20))

        to_download = df_clean.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="\ud83d\udcc5 –°–∫–∞—á–∞—Ç—å –æ—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (CSV)",
            data=to_download,
            file_name="cleaned_data.csv",
            mime="text/csv"
        )

        st.subheader("\ud83d\udcca –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        summary = analyze_with_ai(df_clean)
        st.markdown(summary)

        st.subheader("\ud83e\udd16 AI –ò–Ω—Å–∞–π—Ç—ã –ø–æ –æ—á–∏—â–µ–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º")
        insights = generate_ai_insights(df_clean)
        st.markdown(insights)

        st.subheader("\ud83c\udfa8 –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–º")
        viz_recs = generate_viz_recommendations(df_clean)
        if viz_recs:
            st.markdown(viz_recs)
        else:
            st.info("–ù–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–º.")
    else:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞.")
else:
   st.info("üìÅ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
