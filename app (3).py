import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import openai
import io
import json
import warnings
import tempfile
import hashlib
import traceback
from plotly.subplots import make_subplots
from sklearn.ensemble import IsolationForest
from statsmodels.tsa.seasonal import seasonal_decompose
from pandas.api.types import is_datetime64_any_dtype
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(filename='app_errors.log', level=logging.ERROR,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
warnings.filterwarnings('ignore')
st.set_option('deprecation.showPyplotGlobalUse', False)
pd.options.mode.chained_assignment = None  # –û—Ç–∫–ª—é—á–∞–µ–º SettingWithCopyWarning

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
MAX_ROWS_PREVIEW = 1000
MAX_ROWS_ANALYSIS = 50000
SAMPLE_SIZE = 10000

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="ü§ñ AI Data Analyzer Pro",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ó–∞–≥—Ä—É–∑–∫–∞ API –∫–ª—é—á–∞ OpenAI –∏–∑ Streamlit Secrets
def get_api_key():
    if 'OPENAI_API_KEY' in st.secrets:
        return st.secrets['OPENAI_API_KEY']
    return st.text_input("–í–≤–µ–¥–∏—Ç–µ OpenAI API –∫–ª—é—á:", type="password")

openai.api_key = get_api_key()

# –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π CSS
st.markdown("""
    <style>
        .stApp { background-color: #f0f2f6; color: #000000; }
        footer { visibility: hidden; }
        .stAlert { padding: 15px; border-radius: 10px; }
        .st-b7 { color: #ffffff !important; }
    </style>
""", unsafe_allow_html=True)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç XSS
st.title("ü§ñ AI Data Analyzer Pro")
st.markdown("""
    <div style="background-color:#ffffff;padding:10px;border-radius:10px;margin-bottom:20px;">
    <p style="color:#333;font-size:18px;">üöÄ <b>–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å AI-powered –∏–Ω—Å–∞–π—Ç–∞–º–∏</b></p>
    <p style="color:#666;">–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV, Excel –∏–ª–∏ JSON ‚Äî –ø–æ–ª—É—á–∏—Ç–µ –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é</p>
    </div>
""", unsafe_allow_html=True)

# –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
@st.cache_data(show_spinner="–ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ... ‚è≥", ttl=3600, max_entries=3)
def load_data(uploaded_file):
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
        if uploaded_file.size > MAX_FILE_SIZE:
            st.error(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π! –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE//(1024*1024)}MB")
            return None
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ö–µ—à–∞ —Ñ–∞–π–ª–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
        file_hash = hashlib.md5(uploaded_file.getvalue()).hexdigest()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        with tempfile.NamedTemporaryFile(delete=True, suffix=uploaded_file.name) as tmpfile:
            tmpfile.write(uploaded_file.getvalue())
            tmpfile.flush()
            
            if uploaded_file.name.endswith('.csv'):
                return pd.read_csv(tmpfile.name, encoding_errors='ignore', on_bad_lines='skip')
            elif uploaded_file.name.endswith(('.xlsx', '.xls')):
                return pd.read_excel(tmpfile.name)
            elif uploaded_file.name.endswith('.json'):
                with open(tmpfile.name, 'r') as f:
                    data = json.load(f)
                return pd.json_normalize(data)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}\n{traceback.format_exc()}")
        st.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")
        return None

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ —Å –∑–∞—â–∏—Ç–æ–π
def reduce_mem_usage(df):
    try:
        if df.empty:
            return df
            
        start_mem = df.memory_usage().sum() / 1024**2
        for col in df.columns:
            col_type = df[col].dtype
            if col_type != object:
                c_min = df[col].min()
                c_max = df[col].max()
                if pd.api.types.is_integer_dtype(col_type):
                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                        df[col] = df[col].astype(np.int8)
                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                        df[col] = df[col].astype(np.int16)
                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                        df[col] = df[col].astype(np.int32)
                    else:
                        df[col] = df[col].astype(np.int64)
                else:
                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                        df[col] = df[col].astype(np.float16)
                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                        df[col] = df[col].astype(np.float32)
                    else:
                        df[col] = df[col].astype(np.float64)
        end_mem = df.memory_usage().sum() / 1024**2
        st.sidebar.info(f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏: {start_mem:.2f} MB ‚Üí {end_mem:.2f} MB (—Å—ç–∫–æ–Ω–æ–º–ª–µ–Ω–æ {100*(start_mem-end_mem)/start_mem:.1f}%)")
        return df
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏: {str(e)}\n{traceback.format_exc()}")
        return df

# AI –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –∏–Ω—ä–µ–∫—Ü–∏–π
@st.cache_data(show_spinner="–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ... üîç", ttl=600)
def analyze_with_ai(df):
    try:
        if df.empty or len(df.columns) == 0:
            return "–î–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–ª–æ–Ω–æ–∫"
            
        analysis = f"### üìä –û–±—â–∏–π –æ–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö\n"
        analysis += f"- **–°—Ç—Ä–æ–∫–∏:** {df.shape[0]:,}\n"
        analysis += f"- **–ö–æ–ª–æ–Ω–∫–∏:** {df.shape[1]}\n"
        analysis += f"- **–û–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö:** {df.memory_usage().sum() / 1024**2:.2f} MB\n\n"

        # –ß–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        num_cols = df.select_dtypes(include=np.number).columns
        if len(num_cols) > 0:
            analysis += "### üî¢ –ß–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ\n"
            stats = df[num_cols].describe().transpose()
            stats['skew'] = df[num_cols].skew()
            analysis += stats[['mean', 'std', 'min', '50%', 'max', 'skew']].to_markdown()

        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        cat_cols = df.select_dtypes(exclude=np.number).columns
        if len(cat_cols) > 0:
            analysis += "\n\n### üî§ –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n"
            for col in cat_cols:
                analysis += f"- **{col}**: {df[col].nunique()} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n"

        # –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        missing = df.isnull().sum()
        if missing.sum() > 0:
            analysis += "\n\n### ‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n"
            missing_percent = missing[missing > 0] / len(df) * 100
            missing_df = pd.DataFrame({'–ö–æ–ª–æ–Ω–∫–∞': missing_percent.index,
                                      '–ü—Ä–æ–ø—É—Å–∫–∏': missing[missing > 0],
                                      '%': missing_percent.values.round(1)})
            analysis += missing_df.to_markdown(index=False)

        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        if len(num_cols) > 1:
            corr = df[num_cols].corr().abs().unstack().sort_values(ascending=False)
            strong_corr = corr[(corr > 0.7) & (corr < 1)].drop_duplicates()
            if len(strong_corr) > 0:
                analysis += "\n\n### üîó –°–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏\n"
                for pair, value in strong_corr.items():
                    analysis += f"- {pair[0]} –∏ {pair[1]}: {value:.2f}\n"

        return analysis
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}\n{traceback.format_exc()}")
        return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {str(e)}"

# –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π —Å –∑–∞—â–∏—Ç–æ–π
@st.cache_data(show_spinner="–ò—â—É –∞–Ω–æ–º–∞–ª–∏–∏... üïµÔ∏è", ttl=300)
def detect_anomalies(df, column):
    try:
        if df.empty or column not in df.columns:
            return pd.DataFrame()
            
        if len(df) > SAMPLE_SIZE:
            sample = df.sample(min(5000, len(df)))
        else:
            sample = df

        model = IsolationForest(contamination=0.05, random_state=42, n_jobs=-1)
        model.fit(sample[[column]])
        df['anomaly'] = model.predict(df[[column]])
        anomalies = df[df['anomaly'] == -1]
        return anomalies
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π: {str(e)}\n{traceback.format_exc()}")
        return pd.DataFrame()

# –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Å –∑–∞—â–∏—Ç–æ–π
@st.cache_data(show_spinner="–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã... ‚è≥", ttl=300)
def time_series_analysis(df, date_col, value_col):
    try:
        if df.empty or date_col not in df.columns or value_col not in df.columns:
            return None
            
        df = df.set_index(date_col).sort_index()
        if len(df) > SAMPLE_SIZE:
            df = df.resample('D').mean()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫
        if len(df) < 2:
            return None
            
        period = min(12, max(2, len(df)//2))  # –ó–∞—â–∏—Ç–∞ –æ—Ç –º–∞–ª—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤
        decomposition = seasonal_decompose(df[value_col], period=period, extrapolate_trend='freq')

        fig = make_subplots(rows=4, cols=1, shared_xaxes=True)
        fig.add_trace(go.Scatter(x=df.index, y=df[value_col], name='–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ'), row=1, col=1)
        fig.add_trace(go.Scatter(x=decomposition.trend.index, y=decomposition.trend, name='–¢—Ä–µ–Ω–¥'), row=2, col=1)
        fig.add_trace(go.Scatter(x=decomposition.seasonal.index, y=decomposition.seasonal, name='–°–µ–∑–æ–Ω–Ω–æ—Å—Ç—å'), row=3, col=1)
        fig.add_trace(go.Scatter(x=decomposition.resid.index, y=decomposition.resid, name='–û—Å—Ç–∞—Ç–∫–∏'), row=4, col=1)

        fig.update_layout(height=800, title_text="–î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞")
        return fig
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤: {str(e)}\n{traceback.format_exc()}")
        return None

# –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤
@st.cache_data(show_spinner="–ì–µ–Ω–µ—Ä–∏—Ä—É—é AI –∏–Ω—Å–∞–π—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏... ü§ñ", ttl=600)
def generate_ai_insights_and_viz(df):
    if not openai.api_key:
        return "üîë –ö–ª—é—á OpenAI API –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ Secrets.", None, None, None, None, None, None

    try:
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
        sample_df = df.sample(min(1000, len(df))) if len(df) > 1000 else df
        columns = list(sample_df.columns)
        sample_data = sample_df.head().to_dict()
        
        # –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        safe_columns = json.dumps(columns)
        safe_sample = json.dumps(sample_data)

        prompt = (
            f"–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö. –°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–∞–Ω–Ω—ã–º.\n"
            f"–î–∞–Ω–Ω—ã–µ: {sample_df.shape[0]} —Å—Ç—Ä–æ–∫, {sample_df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫.\n"
            f"–ö–æ–ª–æ–Ω–∫–∏: {safe_columns}.\n"
            f"–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\n{safe_sample}\n\n"
            f"–ù–∞–ø–∏—à–∏ –∏–Ω—Å–∞–π—Ç—ã –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–∏–ø–æ–≤ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –∏–∑ —Å–ø–∏—Å–∫–∞:\n"
            f"- –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞\n- —Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞\n- —Ç–æ—á–µ—á–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞\n- 3D scatter\n"
            f"- –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥\n- candlestick\n- –∞–Ω–æ–º–∞–ª–∏–∏\n- —è—â–∏–∫ —Å —É—Å–∞–º–∏\n"
            f"- —Å—Ç–æ–ª–±—á–∞—Ç–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞\n- –∫—Ä—É–≥–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞\n- scatter —Å —Ç—Ä–µ–Ω–¥–æ–º\n"
            f"- pairplot\n- density plot\n- violin plot\n- treemap\n- area chart\n"
            f"- bubble chart\n- 2D histogram\n- boxen plot\n- –≤—Ä–µ–º–µ–Ω–Ω–æ–π heatmap\n\n"
            f"–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:\n"
            f'{{"insights": "...", "visualizations": [{{"viz_type": "...", "x_axis": "...", "y_axis": "...", "z_axis": "...", "color": "...", "size": "..."}}]}}\n'
        )

        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=600
        )
        text = response['choices'][0]['message']['content'].strip()

        try:
            # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON
            parsed = json.loads(text)
            insights = parsed.get('insights', '')
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
            visualizations = parsed.get('visualizations', [])
            if visualizations:
                viz = visualizations[0]
                return (
                    insights,
                    viz.get('viz_type', None),
                    viz.get('x_axis', None),
                    viz.get('y_axis', None),
                    viz.get('z_axis', None),
                    viz.get('color', None),
                    viz.get('size', None)
                )
            return insights, None, None, None, None, None, None
        except json.JSONDecodeError:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –µ—Å–ª–∏ JSON –Ω–µ–≤–∞–ª–∏–¥–µ–Ω
            return text, None, None, None, None, None, None

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ OpenAI: {str(e)}\n{traceback.format_exc()}")
        return f"–û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ OpenAI API: {str(e)}", None, None, None, None, None, None

# –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
def create_visualization(df, viz_type, x=None, y=None, z=None, color=None, size=None):
    try:
        if df.empty or viz_type is None:
            return None
            
        # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
        viz_df = df.sample(min(SAMPLE_SIZE, len(df))) if len(df) > SAMPLE_SIZE else df
        
        fig = None

        if viz_type == "–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞" and x in viz_df.columns:
            fig = px.histogram(viz_df, x=x, color=color, marginal="box", nbins=50)

        elif viz_type == "–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞":
            num_cols = viz_df.select_dtypes(include=np.number).columns
            if len(num_cols) > 1:
                corr = viz_df[num_cols].corr()
                fig = px.imshow(corr, text_auto=True, color_continuous_scale='RdBu_r', title="–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞")

        elif viz_type == "3D scatter" and all(col in viz_df.columns for col in [x, y, z]):
            fig = px.scatter_3d(viz_df, x=x, y=y, z=z, color=color, size=size)

        elif viz_type == "–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥" and x in viz_df.columns and y in viz_df.columns:
            if is_datetime64_any_dtype(viz_df[x]):
                fig = px.line(viz_df.sort_values(x), x=x, y=y, color=color)

        elif viz_type == "candlestick":
            required = {'open', 'high', 'low', 'close', x}
            if set(required).issubset(set(viz_df.columns)):
                fig = go.Figure(data=[go.Candlestick(
                    x=viz_df[x],
                    open=viz_df['open'],
                    high=viz_df['high'],
                    low=viz_df['low'],
                    close=viz_df['close']
                )])

        elif viz_type == "–∞–Ω–æ–º–∞–ª–∏–∏" and x in viz_df.columns and y in viz_df.columns:
            anomalies = detect_anomalies(viz_df, y)
            if not anomalies.empty:
                fig = px.scatter(viz_df, x=x, y=y, title="–ê–Ω–æ–º–∞–ª–∏–∏ –≤ –¥–∞–Ω–Ω—ã—Ö")
                fig.add_trace(go.Scatter(
                    x=anomalies[x], 
                    y=anomalies[y], 
                    mode='markers',
                    marker=dict(color='red', size=10), 
                    name='–ê–Ω–æ–º–∞–ª–∏–∏'
                ))

        elif viz_type == "—Ç–æ—á–µ—á–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞" and x in viz_df.columns and y in viz_df.columns:
            fig = px.scatter(viz_df, x=x, y=y, color=color, size=size)

        if fig:
            fig.update_layout(height=600, margin=dict(t=50, b=50, l=50, r=50))
            return fig
        return None

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)}\n{traceback.format_exc()}")
        return None

# --- –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å –∑–∞—â–∏—Ç–æ–π ---

uploaded_file = st.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ (.csv, .xlsx, .json)", 
    type=["csv", "xlsx", "xls", "json"],
    accept_multiple_files=False
)

if uploaded_file:
    if uploaded_file.size > MAX_FILE_SIZE:
        st.error(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π! –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE//(1024*1024)}MB")
    else:
        df = load_data(uploaded_file)
        if df is not None:
            if not df.empty:
                df = reduce_mem_usage(df)
                
                st.subheader("–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
                st.dataframe(df.head(min(MAX_ROWS_PREVIEW, len(df))))
                
                # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
                if len(df) > MAX_ROWS_ANALYSIS:
                    st.warning(f"‚ö†Ô∏è –î–∞—Ç—Å–µ—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. –ë—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –ø–µ—Ä–≤—ã–µ {MAX_ROWS_ANALYSIS} —Å—Ç—Ä–æ–∫.")
                    df = df.head(MAX_ROWS_ANALYSIS)
                
                # AI –∞–Ω–∞–ª–∏–∑
                insights, viz_type, x_axis, y_axis, z_axis, color, size = generate_ai_insights_and_viz(df)
                
                st.subheader("ü§ñ AI –∏–Ω—Å–∞–π—Ç—ã")
                st.markdown(insights if insights else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω—Å–∞–π—Ç–æ–≤.")
                
                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                if viz_type:
                    st.subheader(f"üìà –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è: {viz_type}")
                    fig = create_visualization(df, viz_type, x_axis, y_axis, z_axis, color, size)
                    if fig:
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.")
                else:
                    st.info("AI –Ω–µ –ø—Ä–µ–¥–ª–æ–∂–∏–ª –ø–æ–¥—Ö–æ–¥—è—â—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –¥–ª—è –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö.")
                
                # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                with st.expander("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"):
                    st.markdown(analyze_with_ai(df))
                    
                    # –ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π
                    num_cols = df.select_dtypes(include=np.number).columns.tolist()
                    if num_cols:
                        col_for_anom = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —á–∏—Å–ª–æ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–æ–º–∞–ª–∏–π", num_cols)
                        anomalies = detect_anomalies(df, col_for_anom)
                        if not anomalies.empty:
                            st.write(f"–ù–∞–π–¥–µ–Ω–æ {len(anomalies)} –∞–Ω–æ–º–∞–ª–∏–π –≤ —Å—Ç–æ–ª–±—Ü–µ {col_for_anom}")
                            st.dataframe(anomalies.head(20))
                            fig_anom = px.scatter(df, x=df.index, y=col_for_anom, title=f"–ê–Ω–æ–º–∞–ª–∏–∏ –≤ {col_for_anom}")
                            fig_anom.add_trace(go.Scatter(
                                x=anomalies.index, 
                                y=anomalies[col_for_anom],
                                mode='markers', 
                                marker=dict(color='red', size=10),
                                name='–ê–Ω–æ–º–∞–ª–∏–∏'
                            ))
                            st.plotly_chart(fig_anom, use_container_width=True)
                    
                    # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
                    date_cols = df.select_dtypes(include=['datetime', 'datetimetz']).columns.tolist()
                    if not date_cols:
                        # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
                        for c in df.columns:
                            try:
                                df[c] = pd.to_datetime(df[c], errors='coerce')
                                if not df[c].isnull().all():
                                    date_cols.append(c)
                            except:
                                continue
                    
                    if date_cols and num_cols:
                        date_col = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–∞–º–∏", date_cols)
                        value_col = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —á–∏—Å–ª–æ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞", num_cols)
                        fig_ts = time_series_analysis(df, date_col, value_col)
                        if fig_ts:
                            st.plotly_chart(fig_ts, use_container_width=True)
                        else:
                            st.info("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—é –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞.")
            else:
                st.error("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
else:
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")

# –ó–∞—â–∏—Ç–∞ –æ—Ç XSS –≤ –≤—ã–≤–æ–¥–µ
st.markdown("""
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const userContentElements = document.querySelectorAll('.stMarkdown');
            userContentElements.forEach(el => {
                el.innerHTML = el.textContent;
            });
        });
    </script>
""", unsafe_allow_html=True)
