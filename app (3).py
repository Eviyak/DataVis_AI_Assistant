import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import openai
import io
import json
import warnings
import joblib
from datetime import datetime
from sklearn.ensemble import IsolationForest, RandomForestClassifier, RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.cluster import KMeans
from pandas.api.types import is_numeric_dtype, is_categorical_dtype
import matplotlib.pyplot as plt

warnings.filterwarnings('ignore')

st.set_page_config(page_title="DataJournalist ML Assistant", page_icon="üì∞", layout="wide")

if 'OPENAI_API_KEY' in st.secrets:
    openai.api_key = st.secrets['OPENAI_API_KEY']
else:
    openai.api_key = ""

# ==== –°–¢–ò–õ–ò ====
st.markdown("""
    <style>
        .stApp { background-color: #f0f2f6; color: #000000; }
        footer { visibility: hidden; }
    </style>
""", unsafe_allow_html=True)

st.title("üì∞ DataJournalist ML Assistant")
st.markdown("""
    <div style="background-color:#ffffff;padding:20px;border-radius:10px;margin-bottom:20px;">
    <h3 style="color:#333;">üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö + ML</h3>
    <p style="color:#666;">–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ ‚Üí –ø–æ–ª—É—á–∏—Ç–µ –∏–Ω—Å–∞–π—Ç—ã, –º–æ–¥–µ–ª–∏, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏</p>
    </div>
""", unsafe_allow_html=True)

@st.cache_data
def load_data(uploaded_file):
    try:
        file_bytes = uploaded_file.read()
        if uploaded_file.name.endswith('.csv'):
            return pd.read_csv(io.BytesIO(file_bytes)), None
        elif uploaded_file.name.endswith(('.xlsx', '.xls')):
            return pd.read_excel(io.BytesIO(file_bytes)), None
        elif uploaded_file.name.endswith('.json'):
            data = json.loads(file_bytes.decode('utf-8'))
            return pd.json_normalize(data), None
    except Exception as e:
        return None, f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}"

def reduce_mem_usage(df):
    start_mem = df.memory_usage().sum() / 1024**2
    for col in df.columns:
        col_type = df[col].dtype
        if col_type != object:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                else:
                    df[col] = df[col].astype(np.int64)
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
    end_mem = df.memory_usage().sum() / 1024**2
    st.sidebar.info(f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏: {start_mem:.2f} MB ‚Üí {end_mem:.2f} MB")
    return df

def fill_missing_values(df):
    df_filled = df.copy()
    for col in df_filled.columns:
        if df_filled[col].isnull().sum() > 0:
            if is_numeric_dtype(df_filled[col]):
                df_filled[col].fillna(df_filled[col].median(), inplace=True)
            else:
                mode_val = df_filled[col].mode()
                if not mode_val.empty:
                    df_filled[col].fillna(mode_val[0], inplace=True)
                else:
                    df_filled[col].fillna("Unknown", inplace=True)
    return df_filled

def mark_anomalies(df):
    num_cols = df.select_dtypes(include=np.number).columns
    if len(num_cols) == 0:
        return df
    iso = IsolationForest(contamination=0.05, random_state=42)
    preds = iso.fit_predict(df[num_cols])
    df['anomaly'] = preds
    df['anomaly'] = df['anomaly'].map({1: 0, -1: 1})
    return df

def prepare_data_for_ml(df, target_column):
    le = LabelEncoder()
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = le.fit_transform(df[col].astype(str))
    X = df.drop(columns=[target_column])
    y = df[target_column]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    return X_scaled, y, scaler
def generate_shap_plot(model, X_test, feature_names):
    import shap
    explainer = shap.Explainer(model, X_test)
    shap_values = explainer(X_test)
    fig = shap.plots.beeswarm(shap_values, show=False)
    return fig

def generate_ai_report(df, model, problem_type, target, metrics):
    if not openai.api_key:
        return "üîë –ö–ª—é—á OpenAI API –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω."
    prompt = (
        f"–¢—ã –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö. –ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –∂—É—Ä–Ω–∞–ª–∏—Å—Ç—Å–∫–∏–π –æ—Ç—á–µ—Ç –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.\n\n"
        f"–¢–∏–ø –∑–∞–¥–∞—á–∏: {problem_type}\n"
        f"–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {target}\n"
        f"–ú–µ—Ç—Ä–∏–∫–∏: {metrics}\n"
        f"–ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}\n"
        f"–ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:\n{df.head(3).to_dict()}\n\n"
        f"–ù–∞–ø–∏—à–∏ –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n1. –í–≤–µ–¥–µ–Ω–∏–µ\n2. –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã\n3. –ß—Ç–æ –≤–∞–∂–Ω–æ —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å —á–∏—Ç–∞—Ç–µ–ª—é\n"
    )
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "–¢—ã –∂—É—Ä–Ω–∞–ª–∏—Å—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫, –ø–∏—à—É—â–∏–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ–∫—Å—Ç—ã."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=1000
        )
        return response['choices'][0]['message']['content']
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ AI –æ—Ç—á–µ—Ç–∞: {e}"

def generate_flourish_recommendations(df, target):
    prompt = (
        f"–¢—ã –∂—É—Ä–Ω–∞–ª–∏—Å—Ç –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö. –ü–æ —Å–ª–µ–¥—É—é—â–µ–º—É –¥–∞—Ç–∞—Ñ—Ä–µ–π–º—É:\n"
        f"–ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}\n"
        f"–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {target}\n\n"
        f"–ü—Ä–µ–¥–ª–æ–∂–∏ 3 –∏–¥–µ–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ —Å—Ç–∏–ª–µ –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏, –∫–∞–∫ –Ω–∞ —Å–∞–π—Ç–µ –†–ë–ö –∏–ª–∏ BBC. "
        f"–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∑–∏—Å—ã, –±–µ–∑ –∫–æ–¥–∞, –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
    )
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "–¢—ã —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –∂—É—Ä–Ω–∞–ª–∏—Å—Ç–∏–∫–µ."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=600
        )
        return response['choices'][0]['message']['content']
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ AI —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {e}"

# === UI ===
st.sidebar.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
uploaded_file = st.sidebar.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV, Excel –∏–ª–∏ JSON —Ñ–∞–π–ª", type=["csv", "xlsx", "xls", "json"])

if uploaded_file:
    df_raw, error = load_data(uploaded_file)
    if error:
        st.error(error)
    else:
        df_clean = fill_missing_values(df_raw)
        df_clean = mark_anomalies(df_clean)
        df_clean = reduce_mem_usage(df_clean)

        st.success(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_file.name}")
        st.write("### üìÑ –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:")
        st.dataframe(df_clean.head(10), use_container_width=True)

        # –°–∫–∞—á–∞—Ç—å –æ—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        csv_clean = df_clean.to_csv(index=False).encode("utf-8")
        st.download_button("üì• –°–∫–∞—á–∞—Ç—å –æ—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", data=csv_clean, file_name="cleaned_data.csv", mime="text/csv")

        # –í—ã–±–æ—Ä –∑–∞–¥–∞—á–∏
        st.sidebar.header("üß† ML-–∑–∞–¥–∞—á–∞")
        ml_task = st.sidebar.selectbox("–ß—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å?", ["–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ä–µ–≥—Ä–µ—Å—Å–∏—è)", "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è", "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è"])

        if ml_task in ["–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ä–µ–≥—Ä–µ—Å—Å–∏—è)", "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è"]:
            target = st.sidebar.selectbox("–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è", options=df_clean.columns)
            if st.sidebar.button("üöÄ –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å"):
                X, y, scaler = prepare_data_for_ml(df_clean, target)
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                if ml_task == "–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ä–µ–≥—Ä–µ—Å—Å–∏—è)":
                    model = RandomForestRegressor(random_state=42)
                    model.fit(X_train, y_train)
                    preds = model.predict(X_test)
                    rmse = mean_squared_error(y_test, preds, squared=False)
                    metrics = {"RMSE": rmse}
                    problem_type = "regression"

                else:
                    model = RandomForestClassifier(random_state=42)
                    model.fit(X_train, y_train)
                    preds = model.predict(X_test)
                    acc = accuracy_score(y_test, preds)
                    metrics = {"Accuracy": acc}
                    problem_type = "classification"

                st.session_state.update({
                    'model': model,
                    'X_test': X_test,
                    'y_test': y_test,
                    'y_pred': preds,
                    'metrics': metrics,
                    'problem_type': problem_type,
                    'feature_names': df_clean.drop(columns=[target]).columns,
                    'df': df_clean,
                    'target': target
                })
                st.experimental_rerun()

        elif ml_task == "–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è":
            num_cols = df_clean.select_dtypes(include=np.number).columns
            n_clusters = st.sidebar.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤", min_value=2, max_value=10, value=3)
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            df_clustered = df_clean.copy()
            df_clustered["Cluster"] = kmeans.fit_predict(df_clustered[num_cols])
            cluster_means = df_clustered.groupby("Cluster")[num_cols].mean().round(2)

            st.session_state.update({
                'df_clustered': df_clustered,
                'cluster_analysis': cluster_means,
                'model': kmeans
            })
            st.experimental_rerun()
# –í–∏–∑—É–∞–ª—å–Ω—ã–µ –≤–∫–ª–∞–¥–∫–∏
if 'model' in st.session_state or 'df_clustered' in st.session_state:
    tabs = st.tabs(["üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã", "üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è", "üìù –ñ—É—Ä–Ω–∞–ª–∏—Å—Ç—Å–∫–∏–π –æ—Ç—á–µ—Ç", "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏"])

    # === –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ===
    with tabs[0]:
        st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏")
        if st.session_state.get('problem_type') == "classification":
            st.write("**–ú–µ—Ç—Ä–∏–∫–∏:**")
            st.json(st.session_state['metrics'])

            cm = confusion_matrix(st.session_state['y_test'], st.session_state['y_pred'])
            st.write("**–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:**")
            fig, ax = plt.subplots()
            disp = ConfusionMatrixDisplay(confusion_matrix=cm)
            disp.plot(ax=ax)
            st.pyplot(fig)

        elif st.session_state.get('problem_type') == "regression":
            st.write("**RMSE:**", round(st.session_state['metrics']['RMSE'], 3))

        elif 'df_clustered' in st.session_state:
            st.write("**–°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:**")
            st.dataframe(st.session_state['cluster_analysis'])

    # === –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è ===
    with tabs[1]:
        st.subheader("üìà –ü—Ä–æ—Å—Ç–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è")
        df_vis = st.session_state.get('df', pd.DataFrame())
        if not df_vis.empty:
            x = st.selectbox("–û—Å—å X", options=df_vis.columns)
            y = st.selectbox("–û—Å—å Y", options=df_vis.columns)
            chart = px.scatter(df_vis, x=x, y=y, color_discrete_sequence=["#1f77b4"])
            st.plotly_chart(chart, use_container_width=True)

    # === –ñ—É—Ä–Ω–∞–ª–∏—Å—Ç—Å–∫–∏–π –æ—Ç—á–µ—Ç ===
    with tabs[2]:
        st.subheader("üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∂—É—Ä–Ω–∞–ª–∏—Å—Ç—Å–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞")
        report = generate_ai_report(
            st.session_state['df'],
            st.session_state['model'],
            st.session_state['problem_type'],
            st.session_state['target'],
            st.session_state['metrics']
        )
        st.markdown(report)

        st.subheader("üéØ –ò–¥–µ–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –≤ Flourish")
        flourish_tips = generate_flourish_recommendations(st.session_state['df'], st.session_state['target'])
        st.markdown(flourish_tips)

    # === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ / –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ ===
    with tabs[3]:
        st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        st.write("–í–µ—Ä—Å–∏—è: 1.0.0")
        st.write("–ê–≤—Ç–æ—Ä: DataJournalist Assistant by GPT")
        st.markdown("GitHub: [—Å—Å—ã–ª–∫–∞-–∑–¥–µ—Å—å](https://github.com/your-project)")
        st.markdown("–ï—Å–ª–∏ –≤—ã –∑–∞–º–µ—Ç–∏–ª–∏ –æ—à–∏–±–∫—É ‚Äî –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫—É.")
