# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EJssdbxYBluvPtxioJpupUZH3Q805Jzv
"""

pip install streamlit pandas matplotlib seaborn scikit-learn fpdf openpyxl xlsxwriter

import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import json
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.metrics import accuracy_score, confusion_matrix, r2_score
from sklearn.preprocessing import LabelEncoder
import numpy as np
from fpdf import FPDF
import io

st.set_page_config(page_title="üìä AI –í–∏–∑—É–∞–ª–∏–∑–∞—Ç–æ—Ä –∏ ML –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä", layout="wide")
st.title("üìä AI-–ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏ ML —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ—Ç—á—ë—Ç–æ–º")
st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV, Excel –∏–ª–∏ JSON ‚Äî –ø–æ–ª—É—á–∏—Ç–µ –∞–Ω–∞–ª–∏–∑, ML-–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ PDF-–æ—Ç—á—ë—Ç.")

def load_data(uploaded_file):
    try:
        if uploaded_file.name.endswith('.csv'):
            return pd.read_csv(uploaded_file)
        elif uploaded_file.name.endswith(('.xlsx', '.xls')):
            return pd.read_excel(uploaded_file)
        elif uploaded_file.name.endswith('.json'):
            data = json.load(uploaded_file)
            if isinstance(data, list):
                return pd.DataFrame(data)
            else:
                st.error("JSON –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤.")
                return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")
        return None

def save_fig_to_buffer(fig):
    buf = io.BytesIO()
    fig.savefig(buf, format='png')
    buf.seek(0)
    plt.close(fig)
    return buf

def generate_pdf_report(df, target, task, metrics, feature_importance, figs):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", 'B', 16)
    pdf.cell(0, 10, "–û—Ç—á—ë—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∏ ML", ln=True, align='C')

    pdf.set_font("Arial", size=12)
    pdf.ln(10)
    pdf.cell(0, 10, f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {df.shape[0]}", ln=True)
    pdf.cell(0, 10, f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {df.shape[1]}", ln=True)
    pdf.cell(0, 10, f"–¶–µ–ª–µ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü: {target}", ln=True)
    pdf.cell(0, 10, f"–¢–∏–ø –∑–∞–¥–∞—á–∏: {task}", ln=True)

    pdf.ln(10)
    pdf.cell(0, 10, "–ú–µ—Ç—Ä–∏–∫–∏:", ln=True)
    for k, v in metrics.items():
        pdf.cell(0, 10, f"{k}: {v}", ln=True)

    pdf.ln(10)
    pdf.cell(0, 10, "–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:", ln=True)
    for feat, val in feature_importance.items():
        pdf.cell(0, 10, f"{feat}: {val:.3f}", ln=True)

    pdf.ln(10)
    for i, fig_buf in enumerate(figs):
        pdf.image(fig_buf, x=10, w=180)
        pdf.ln(85)

    return pdf.output(dest='S').encode('latin1')

def basic_ml_analysis(df):
    st.subheader("ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π ML-–∞–Ω–∞–ª–∏–∑")

    target = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ü–µ–ª–µ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü (–¥–ª—è ML –∞–Ω–∞–ª–∏–∑–∞)", df.columns)
    if not target:
        return None

    X = df.drop(columns=[target])
    y = df[target]

    X_processed = X.copy()
    for col in X_processed.columns:
        if X_processed[col].dtype == 'object':
            X_processed[col] = X_processed[col].fillna('missing')
            le = LabelEncoder()
            X_processed[col] = le.fit_transform(X_processed[col])
        else:
            X_processed[col] = X_processed[col].fillna(X_processed[col].mean())

    if y.dtype == 'object':
        y = y.fillna('missing')
        le_target = LabelEncoder()
        y = le_target.fit_transform(y)
    else:
        y = y.fillna(y.mean())

    if len(np.unique(y)) <= 20 and y.dtype in [np.int64, np.int32, np.int16]:
        task = 'classification'
    elif y.dtype in [np.float64, np.float32]:
        task = 'regression'
    else:
        st.info("–¶–µ–ª–µ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü –∏–º–µ–µ—Ç –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –¥–ª—è ML –∞–Ω–∞–ª–∏–∑–∞.")
        return None

    X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.3, random_state=42)

    figs = []
    metrics = {}
    feature_importance = {}

    if task == 'classification':
        st.write("–ó–∞–¥–∞—á–∞: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è")
        model = LogisticRegression(max_iter=1000)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        acc = accuracy_score(y_test, y_pred)
        st.write(f"Accuracy –Ω–∞ —Ç–µ—Å—Ç–µ: **{acc:.2f}**")
        metrics['Accuracy'] = f"{acc:.2f}"

        cm = confusion_matrix(y_test, y_pred)
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt='d', ax=ax)
        ax.set_title("Confusion Matrix")
        st.pyplot(fig)
        figs.append(save_fig_to_buffer(fig))

        coef = pd.Series(model.coef_[0], index=X.columns)
        coef_abs = coef.abs().sort_values(ascending=False)
        st.write("–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –º–æ–¥–µ–ª–∏):")
        st.bar_chart(coef_abs)
        feature_importance = coef_abs.to_dict()

    elif task == 'regression':
        st.write("–ó–∞–¥–∞—á–∞: –†–µ–≥—Ä–µ—Å—Å–∏—è")
        model = LinearRegression()
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        r2 = r2_score(y_test, y_pred)
        st.write(f"R¬≤ –Ω–∞ —Ç–µ—Å—Ç–µ: **{r2:.2f}**")
        metrics['R¬≤'] = f"{r2:.2f}"

        fig, ax = plt.subplots()
        ax.scatter(y_test, y_pred, alpha=0.5)
        ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
        ax.set_xlabel("–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
        ax.set_ylabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ")
        ax.set_title("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏—Å—Ç–∏–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
        st.pyplot(fig)
        figs.append(save_fig_to_buffer(fig))

        coef = pd.Series(model.coef_, index=X.columns)
        coef_abs = coef.abs().sort_values(ascending=False)
        st.write("–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –º–æ–¥–µ–ª–∏):")
        st.bar_chart(coef_abs)
        feature_importance = coef_abs.to_dict()

    if st.button("üìÑ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å PDF-–æ—Ç—á—ë—Ç"):
        pdf_bytes = generate_pdf_report(df, target, task, metrics, feature_importance, figs)
        st.download_button("–°–∫–∞—á–∞—Ç—å –æ—Ç—á—ë—Ç", pdf_bytes, file_name="report.pdf", mime="application/pdf")

    return None

st.write("### –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª", type=["csv", "xlsx", "xls", "json"])

if uploaded_file:
    df = load_data(uploaded_file)

    if df is not None:
        st.subheader("üîç –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        st.write(f"–°—Ç—Ä–æ–∫: {df.shape[0]}, –ö–æ–ª–æ–Ω–æ–∫: {df.shape[1]}")

        tab1, tab2, tab3, tab4 = st.tabs(["–î–∞–Ω–Ω—ã–µ", "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", "–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è", "ML –ê–Ω–∞–ª–∏–∑"])

        with tab1:
            st.dataframe(df.head())

        with tab2:
            st.write("–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:")
            st.write(df.dtypes)
            st.write("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
            st.write(df.isnull().sum())

        with tab3:
            num_cols = df.select_dtypes(include=["number"]).columns
            if len(num_cols) > 0:
                selected_num = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —á–∏—Å–ª–æ–≤—É—é –∫–æ–ª–æ–Ω–∫—É", num_cols)
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
                sns.histplot(df[selected_num], ax=ax1, kde=True)
                sns.boxplot(x=df[selected_num], ax=ax2)
                st.pyplot(fig)

            cat_cols = df.select_dtypes(include=["object", "category"]).columns
            if len(cat_cols) > 0:
                selected_cat = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—É—é –∫–æ–ª–æ–Ω–∫—É", cat_cols)
                fig, ax = plt.subplots()
                df[selected_cat].value_counts().plot(kind='bar', ax=ax)
                st.pyplot(fig)

        with tab4:
            basic_ml_analysis(df)
else:
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ ML")